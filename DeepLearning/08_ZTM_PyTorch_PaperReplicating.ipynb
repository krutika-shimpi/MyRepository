{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 08_ZTM_PyTorch Paper Replicating\n",
        "\n",
        "The goal of machine learning research paper replicating is: turn a ML research paper into usable code.\n",
        "\n",
        "In this notebook we're going to be replicating the Vision Transformer (ViT) architecture/paper with PyTorch.\n",
        "\n",
        "Paper: https://arxiv.org/abs/2010.11929"
      ],
      "metadata": {
        "id": "hdzgHf2TDgx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Get setup\n",
        "\n",
        "Let's import code we've previously written and required libraries."
      ],
      "metadata": {
        "id": "EmB6y-ZmUil8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "    from helper_functions import download_data, set_seeds, plot_loss_curves"
      ],
      "metadata": {
        "id": "2EGtr9UPUiqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ffe5979-0c50-40fc-c58d-02d58f7b4eb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Total 4056 (delta 0), reused 0 (delta 0), pack-reused 4056\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 646.90 MiB | 32.14 MiB/s, done.\n",
            "Resolving deltas: 100% (2371/2371), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lvZ-FYuVjHdQ",
        "outputId": "3ddf98bc-0232-44ba-a349-df65b9684389"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get Data\n",
        "\n",
        "The whole goal of what we're trying to do is replicate the ViT architecture for our FoodVision Mini problem.\n",
        "\n",
        "To do that, we need some data:\n",
        "\n",
        "Namely, the pizza, steak and sushi images we've been using so far."
      ],
      "metadata": {
        "id": "PYbH4ynwjUiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pizza, steak, sushi images from GitHub\n",
        "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                           destination=\"pizza_steak_sushi\")\n",
        "image_path"
      ],
      "metadata": {
        "id": "eGk6NjgCUium",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d359107e-9c0c-4607-83ce-af141f09533b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup directory path\n",
        "train_dir = image_path / 'train'\n",
        "test_dir = image_path / 'test'"
      ],
      "metadata": {
        "id": "SMU82QOKUiyf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Datasets and DataLoaders\n"
      ],
      "metadata": {
        "id": "Vflj_DyFUi3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "from torchvision import transforms\n",
        "\n",
        "# CReate image size\n",
        "IMG_SIZE = 224 # comes from table 3 of ViT paper\n",
        "\n",
        "# Create transforms pipeline\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "print(f\"Manually created transforms:{manual_transforms}\")"
      ],
      "metadata": {
        "id": "k_K0ytdKUi78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "591a25c0-ef3c-42f5-aa5f-e8bfc43ba8b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually created transforms:Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
            "    ToTensor()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a batch size of 32 (the paper uses 4096 but this may be too big for our cpu)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "9wdVd-cMUjAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-C4YqkwZUjEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cEEtHzomUjJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1zr2okzEUjNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Azjbj9IUjRW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}